Done:
Added more data, now 2295 ETFs
Fix error when there's only one ETF matching filters
Color ETFs in portfolio differently
Removed shorting
Improved results table
Simplified deployment using GKE

Questions:
Sorting ETFs by yearReturnPerRiskCUR or by volatilityYearCUR?
Eikon alternative: https://pandas-datareader.readthedocs.io/en/latest/remote_data.html (yfinance or alpha vantage)
Eikon isn't perfect: data fetching is slow, some ETFs have a lot less data than they should have, some ETFs are using data from other very similar ETFs, some data is completely wrong
Negative return - Lyxor S&P 500 VIX Futures Enhanced Roll UCITS ETF - Acc - what is going on with this EFT? Volatility hedging?

TO DO:
Returns don't seem correct (probably using wrong data)
Investigate asset with negative return
Improve README

Back-testing TODO:
Implement system to perform back-testing
Optimize portfolio starting on x date, reoptimizing every x days, based on last x days of data
Check final value
Compare with expected results
Plot results and compare with expected results

PyPortfolioOpt optimizations:
Why is the leftover value so large for large initial values?
Look at other covariance matrix algorithms - Ledoit Wolf
Add constraints: maximum weight for single asset and maximum number of assets
Check L2 regularization (check if it changes the number of ETFs in the portfolio)

Future:
Select multiple filters at once
Allow to upload isin list as csv
Check if ETF list size can be reduced in backend so it doesn't use as much memory (or maybe write etfData to file and read it from there)
Add regime switching optimization
Add other filters: listings, region, sector, equity class (Maybe need to scrape justETF to get more information)


Unsolved questions:
Where to deploy? LRZ has a service that we could maybe use
Fix and understand "covariance matrix is non positive semidefinite" warning (Example: "IE00B99FL386", "LU2090062865", "IE00BFWFPY67", "IE00B7MXFZ59", "LU1291109616", "LU0659579063", "DE000A0D8Q23")



Useful commands:

Mongo:
python -c "import mongoDB; mongoDB.clear_test_db()"
python retrieveData.py
data-pipeline/copy_test_db_to_prod_db.bat
MongoDB export: mongoexport -h localhost:2717 -d prod -c etfs -o etfData.json --jsonArray --pretty
MongoDB import: mongoimport "mongodb://34.89.148.57:2717" --jsonArray -d prod -c etfs --file etfData.json
mongodump --host %MONGO_DB_HOST% --db test
mongo --host %MONGO_DB_HOST% prod --eval "db.dropDatabase()"
mongorestore --host %MONGO_DB_HOST% --db prod dump/test

Docker:
docker build -t gcr.io/etfoptimizer/optimizer:v1 src/.
docker push gcr.io/etfoptimizer/optimizer:v1
kubectl rollout restart deployment/optimizer-deployment

docker build -t gcr.io/etfoptimizer/frontend:v1 frontend/.
docker push gcr.io/etfoptimizer/frontend:v1
kubectl rollout restart deployment/frontend-deployment


